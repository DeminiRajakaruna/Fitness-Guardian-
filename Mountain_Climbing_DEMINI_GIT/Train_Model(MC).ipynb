{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6124cae69cdd5bfa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bfb4514",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\__init__.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kde\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelDensity\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lof\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocalOutlierFactor\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeighborhoodComponentsAnalysis\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VALID_METRICS, VALID_METRICS_SPARSE\n\u001b[0;32m     20\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBallTree\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistanceMetric\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKDTree\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID_METRICS\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     37\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID_METRICS_SPARSE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_nca.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, TransformerMixin\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\decomposition\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_incremental_pca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IncrementalPCA\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kernel_pca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelPCA\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparse_pca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparsePCA, MiniBatchSparsePCA\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_truncated_svd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TruncatedSVD\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fastica\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastICA, fastica\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\decomposition\\_sparse_pca.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state, check_array\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ridge_regression\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, TransformerMixin\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dict_learning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dict_learning, dict_learning_online\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\__init__.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianRidge, ARDRegression\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_least_angle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Lars, LassoLars, lars_path, lars_path_gram, LarsCV,\n\u001b[0;32m     13\u001b[0m                            LassoLarsCV, LassoLarsIC)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_coordinate_descent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Lasso, ElasticNet, LassoCV, ElasticNetCV,\n\u001b[0;32m     15\u001b[0m                                   lasso_path, enet_path, MultiTaskLasso,\n\u001b[0;32m     16\u001b[0m                                   MultiTaskElasticNet, MultiTaskElasticNetCV,\n\u001b[0;32m     17\u001b[0m                                   MultiTaskLassoCV)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_huber\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuberRegressor\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:30\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvergenceWarning\n\u001b[0;32m     26\u001b[0m SOLVE_TRIANGULAR_ARGS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck_finite\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlars_path\u001b[39m(X, y, Xy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, Gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, alpha_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m---> 30\u001b[0m               method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlar\u001b[39m\u001b[38;5;124m'\u001b[39m, copy_X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, eps\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfinfo(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m)\u001b[38;5;241m.\u001b[39meps,\n\u001b[0;32m     31\u001b[0m               copy_Gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, return_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     32\u001b[0m               return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Least Angle Regression or Lasso path using LARS algorithm [1]\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    The optimization objective for the case method='lasso' is::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m Gram \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Datasets/label.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming 'Label' is the column indicating whether it's a in or not\n",
    "X = df.drop(['Label'], axis=1)  # Features\n",
    "y = df['Label']  # Labels\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=255)\n",
    "\n",
    "\n",
    "##############################################K-Nearest Neighbors (KNN)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"Accuracy K-Nearest Neighbors: {accuracy_knn:.2%}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report: K-Nearest Neighbors\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "########################################################XGBoost (Extreme Gradient Boosting)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using XGBoost\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"Accuracy XGBoost: {accuracy_xgb:.2%}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report: XGBoost\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "#########################################################Random Forest \n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "# Train the Random Forest model\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using Random Forest\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy Random Forest: {accuracy_rf:.2%}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report: Random Forest\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "######################################################LightGBM (Light Gradient Boosting Machine)\n",
    "\n",
    "# Initialize the LightGBM classifier\n",
    "lgbm = LGBMClassifier()\n",
    "\n",
    "# Train the LightGBM model\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using LightGBM\n",
    "y_pred_lgbm = lgbm.predict(X_test)\n",
    "\n",
    "# Evaluate the LightGBM model\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "print(f\"Accuracy LightGBM: {accuracy_lgbm:.2%}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report: LightGBM\")\n",
    "print(classification_report(y_test, y_pred_lgbm))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a900bc7",
   "metadata": {},
   "source": [
    "Test model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Predicted Labels: K-Nearest Neighbors [1 0]\n",
      "Accuracy:K-Nearest Neighbors 99.95%\n",
      "Classification Report: K-Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       777\n",
      "           1       1.00      1.00      1.00      1138\n",
      "\n",
      "    accuracy                           1.00      1915\n",
      "   macro avg       1.00      1.00      1.00      1915\n",
      "weighted avg       1.00      1.00      1.00      1915\n",
      "\n",
      "Unique Predicted Labels:XGBoost [1 0]\n",
      "Accuracy:XGBoost 99.95%\n",
      "Classification Report: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       777\n",
      "           1       1.00      1.00      1.00      1138\n",
      "\n",
      "    accuracy                           1.00      1915\n",
      "   macro avg       1.00      1.00      1.00      1915\n",
      "weighted avg       1.00      1.00      1.00      1915\n",
      "\n",
      "Unique Predicted Labels:Random Forest  [1 0]\n",
      "Accuracy:Random Forest  100.00%\n",
      "Classification Report: Random Forest \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       777\n",
      "           1       1.00      1.00      1.00      1138\n",
      "\n",
      "    accuracy                           1.00      1915\n",
      "   macro avg       1.00      1.00      1.00      1915\n",
      "weighted avg       1.00      1.00      1.00      1915\n",
      "\n",
      "Unique Predicted Labels:LightGBM [1 0]\n",
      "Accuracy:LightGBM 99.95%\n",
      "Classification Report: LightGBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       777\n",
      "           1       1.00      1.00      1.00      1138\n",
      "\n",
      "    accuracy                           1.00      1915\n",
      "   macro avg       1.00      1.00      1.00      1915\n",
      "weighted avg       1.00      1.00      1.00      1915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the new dataset with unlabeled data\n",
    "file_path_new = 'Datasets/label.xlsx'\n",
    "df_new = pd.read_excel(file_path_new)\n",
    "\n",
    "# Assuming 'Label' is the column indicating whether it's a video or not in the original labeled dataset\n",
    "X_new = df_new.drop(['Label'], axis=1)   # Features\n",
    "\n",
    "\n",
    "####################################################K-Nearest Neighbors\n",
    "\n",
    "# Use the trained KNN model to predict labels for the new dataset\n",
    "y_pred_new_knn = knn.predict(X_new)\n",
    "\n",
    "# Check unique values in predicted labels\n",
    "unique_labels_knn = pd.Series(y_pred_new_knn).unique()\n",
    "print(\"Unique Predicted Labels: K-Nearest Neighbors\", unique_labels_knn)\n",
    "\n",
    "accuracy_knn = accuracy_score(df_new['Label'], y_pred_new_knn)\n",
    "print(f\"Accuracy:K-Nearest Neighbors {accuracy_knn:.2%}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report: K-Nearest Neighbors\")\n",
    "print(classification_report(df_new['Label'] ,y_pred_new_knn))\n",
    "\n",
    "\n",
    "\n",
    "##########################################XGBoost (Extreme Gradient Boosting)\n",
    "\n",
    "# Use the trained XGBoost model to predict labels for the new dataset\n",
    "y_pred_new_xgb = xgb.predict(X_new)\n",
    "\n",
    "# Check unique values in predicted labels\n",
    "unique_labels_xgb = pd.Series(y_pred_new_xgb).unique()\n",
    "print(\"Unique Predicted Labels:XGBoost\", unique_labels_xgb)\n",
    "\n",
    "accuracy_xgb = accuracy_score(df_new['Label'], y_pred_new_xgb)\n",
    "print(f\"Accuracy:XGBoost {accuracy_xgb:.2%}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report: XGBoost\")\n",
    "print(classification_report(df_new['Label'], y_pred_new_xgb))\n",
    "\n",
    "\n",
    "##############################################Random Forest \n",
    "\n",
    "# Use the trained RF model to predict labels for the new dataset\n",
    "y_pred_new_rf = random_forest.predict(X_new)\n",
    "\n",
    "# Check unique values in predicted labels\n",
    "unique_labels_rf = pd.Series(y_pred_new_rf).unique()\n",
    "print(\"Unique Predicted Labels:Random Forest \", unique_labels_rf)\n",
    "\n",
    "accuracy_rf = accuracy_score(df_new['Label'], y_pred_new_rf)\n",
    "print(f\"Accuracy:Random Forest  {accuracy_rf:.2%}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report: Random Forest \")\n",
    "print(classification_report(df_new['Label'], y_pred_new_rf))\n",
    "\n",
    "\n",
    "# #######################################################################confusion matrix(XGBoost)\n",
    "# # Use the trained KNN model to predict labels for the test set\n",
    "# y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# # Generate confusion matrix \n",
    "# conf_matrix_xgb = confusion_matrix(y_test, y_pred_new_xgb)\n",
    "# # Visualize the confusion matrix \n",
    "# plt.figure(figsize=(2, 2))\n",
    "# sns.heatmap(conf_matrix_xgb, annot=True, fmt='d', cmap='Blues', xticklabelsxgb=xgb.classes_, yticklabelsxgb=xgb.classes_)\n",
    "# plt.title('Confusion Matrix for XGBoost')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################LightGBM (Light Gradient Boosting Machine)\n",
    "# Use the trained LGBM model to predict labels for the new dataset\n",
    "y_pred_new_lgbm = lgbm.predict(X_new)\n",
    "\n",
    "# Check unique values in predicted labels\n",
    "unique_labels_lgbm = pd.Series(y_pred_new_lgbm).unique()\n",
    "print(\"Unique Predicted Labels:LightGBM\", unique_labels_lgbm)\n",
    "\n",
    "accuracy_lgbm = accuracy_score(df_new['Label'], y_pred_new_lgbm)\n",
    "print(f\"Accuracy:LightGBM {accuracy_lgbm:.2%}\")\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report: LightGBM\")\n",
    "print(classification_report(df_new['Label'], y_pred_new_lgbm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "870de6dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, accuracy_score, classification_report\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\__init__.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kde\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelDensity\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lof\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocalOutlierFactor\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_nca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeighborhoodComponentsAnalysis\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VALID_METRICS, VALID_METRICS_SPARSE\n\u001b[0;32m     20\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBallTree\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistanceMetric\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKDTree\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID_METRICS\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     37\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVALID_METRICS_SPARSE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_nca.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, TransformerMixin\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\decomposition\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_incremental_pca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IncrementalPCA\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kernel_pca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelPCA\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparse_pca\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparsePCA, MiniBatchSparsePCA\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_truncated_svd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TruncatedSVD\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fastica\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastICA, fastica\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\decomposition\\_sparse_pca.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state, check_array\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ridge_regression\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, TransformerMixin\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dict_learning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dict_learning, dict_learning_online\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\__init__.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianRidge, ARDRegression\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_least_angle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Lars, LassoLars, lars_path, lars_path_gram, LarsCV,\n\u001b[0;32m     13\u001b[0m                            LassoLarsCV, LassoLarsIC)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_coordinate_descent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Lasso, ElasticNet, LassoCV, ElasticNetCV,\n\u001b[0;32m     15\u001b[0m                                   lasso_path, enet_path, MultiTaskLasso,\n\u001b[0;32m     16\u001b[0m                                   MultiTaskElasticNet, MultiTaskElasticNetCV,\n\u001b[0;32m     17\u001b[0m                                   MultiTaskLassoCV)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_huber\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuberRegressor\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:30\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvergenceWarning\n\u001b[0;32m     26\u001b[0m SOLVE_TRIANGULAR_ARGS \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck_finite\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlars_path\u001b[39m(X, y, Xy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, Gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, alpha_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m---> 30\u001b[0m               method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlar\u001b[39m\u001b[38;5;124m'\u001b[39m, copy_X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, eps\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfinfo(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m)\u001b[38;5;241m.\u001b[39meps,\n\u001b[0;32m     31\u001b[0m               copy_Gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, return_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     32\u001b[0m               return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Least Angle Regression or Lasso path using LARS algorithm [1]\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    The optimization objective for the case method='lasso' is::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m Gram \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Dee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import tarin_test_split\n",
    "\n",
    "\n",
    "# Load the  dataset \n",
    "New_Data_path = 'Datasets/Processed_Dataset.xlsx'\n",
    "df_new = pd.read_excel(New_Data_path)\n",
    "\n",
    "# Assuming 'Label' is the column indicating whether it's a video or not in the train dataset\n",
    "X_new = df_new.drop(['Label'], axis=1)   # Features\n",
    "\n",
    "\n",
    "# Use the trained KNN model to predict labels for the test set\n",
    "y_pred_random = random_forest.predict(X_test)\n",
    "\n",
    "# Generate confusion matrix \n",
    "conf_matrix_random = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "# Visualize the confusion matrix \n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(conf_matrix_random, annot=True, fmt='d', cmap='Blues', xticklabels=knn.classes_, yticklabels=knn.classes_)\n",
    "plt.title('Confusion Matrix for K-Nearest Neighbors')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94e1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c6d5f052e14a7d1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16eb01fb1c3b12f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-18T11:22:06.951130300Z",
     "start_time": "2024-02-18T11:22:06.908652300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Model/modelMC.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a file\n",
    "model_filename = 'Model/modelMC.pkl'\n",
    "\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(random_forest, model_file)\n",
    "\n",
    "print(f\"Model saved as {model_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
